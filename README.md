# Анализ данных с использованием Python, SQL и машинного обучения
## Общая информация
### Описание:
Проект охватывает все аспекты работы с данными: от их загрузки и очистки до визуализации и построения моделей машинного обучения. Это комплексное решение позволяет изучить весь цикл анализа данных на реальных примерах. Проект строится вокруг задач, направленных на развитие навыков предобработки данных, работы с SQL, визуализации и применения алгоритмов машинного обучения.
### Стек технологий:
- Язык программирования: Python
- Библиотеки и инструменты:
  * Анализ данных: Pandas, NumPy
  * Работа с базами данных: SQLite
  * Машинное обучение: scikit-learn
  * Визуализация данных: Matplotlib, Seaborn, Plotly
- Среда разработки: Jupyter Notebook
- Средства контроля версий: Git
### Навыки, полученные в проекте:
1) Загрузка, предобработка и обогащение данных с использованием Pandas.
2) Работа с SQL для извлечения данных и создания аналитических таблиц (DataMart).
3) Применение методов машинного обучения: классификация (Logistic Regression, SVM, Decision Tree), регрессия, кластеризация (KMeans, DBSCAN, Agglomerative Clustering).
4) Визуализация данных и интерпретация графиков.
## Основные этапы и достижения
### 1. Предобработка данных
- Обработка пропущенных значений: замена средними, предыдущими значениями или удаление.
- Выявление и удаление дубликатов в наборах данных.
- Вычисление и добавление новых признаков, таких как временные категории, статистические метрики и индексы активности.
- Конвертация данных в удобные форматы для дальнейшей работы: CSV, JSON, SQL.
### 2. Работа с базами данных (SQL)
- Извлечение данных: Работа с большими таблицами в SQLite для фильтрации и выборки только необходимых данных.
- Создание DataMart: Объединение таблиц с целью подготовки единого источника для анализа.
- Подготовка аналитических отчетов: Агрегирование данных, вычисление метрик, таких как медиана, дисперсия, и коэффициенты корреляции.
### 3. Машинное обучение
- Классификация:
  * Логистическая регрессия (Logistic Regression) для бинарной классификации рабочих и выходных дней.
  * Подбор оптимальных параметров моделей (например, ядра для SVM) и интерпретация результатов.
  * Деревья решений и случайные леса (Decision Tree, Random Forest) для оценки важности признаков.
- Регрессия:
  * Построение моделей линейной регрессии для предсказания временных интервалов выполнения задач.
- Кластеризация:
  * Реализация алгоритмов KMeans, DBSCAN и иерархической кластеризации (Agglomerative Clustering).
  * Оценка качества кластеризации через silhouette_score.
  * Визуализация результатов кластеризации для анализа структуры данных.
### 4. A/B-тестирование
- Проверка гипотез о влиянии новостной ленты на поведение пользователей.
- Сравнение двух групп (тестовой и контрольной) на основе временных метрик.
- Расчет среднего времени до выполнения задания до и после первого посещения новостной ленты.
### 5. Визуализация данных
- Линейные графики, отображающие активность студентов в разные дни.
- Сравнительный анализ активности в будни и выходные.
- Построение тепловых карт (heatmap) для выявления корреляций между признаками.
- Создание дендрограмм для визуализации иерархической кластеризации.
- Демонстрация границ решений (decision boundaries) для моделей классификации.
## Примеры результатов
- Подготовлен DataMart, объединяющий данные о посещениях новостной ленты и выполнении заданий.
- Проведено A/B-тестирование, подтверждающее эффективность введения новостной ленты.
- Построены визуализации, отражающие динамику активности студентов в зависимости от времени суток и дня недели.
- Выявлены ключевые признаки, влияющие на поведение пользователей, такие как время первого коммита, активность в будни и выходные.
